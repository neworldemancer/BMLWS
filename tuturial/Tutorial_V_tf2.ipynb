{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Tutorial_V_tf2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r-csPGkyt2NU",
        "6rPsRTmIt2NR",
        "smZh6bC3xSc0",
        "RAJ6Lsurt2Ne",
        "CNbOLvQYt2Nr",
        "DIQpBhAGO-3O",
        "pwH_H7b6t2N1",
        "Wh0y_Hr4t2N5",
        "6Rc9mTd-t2OM",
        "2K71p8F0t2OS",
        "MN0LvX7dt2Of",
        "Bj0ra0Cpt2Og",
        "1u0_qadxt2Ok",
        "q5x83mdht2Ol",
        "FxfnvGort2Om",
        "lwcVPGjtt2Oo",
        "azGK6ie4Q05I"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXHZ24Eyt2NN"
      },
      "source": [
        "# Tutorial V: Deep models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fcuv4BIt2NP"
      },
      "source": [
        "<p>\n",
        "Bern Winter School on Machine Learning, 2021<br>\n",
        "Prepared by Mykhailo Vladymyrov.\n",
        "</p>\n",
        "\n",
        "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sVP5taKt2NQ"
      },
      "source": [
        "In this session we will use the pretrained Inception model to build own image classifier. We will aslo learn how to save our trained models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-csPGkyt2NU"
      },
      "source": [
        "## 1. Load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJDyIDLtRhE7"
      },
      "source": [
        "colab = True # set to True is using google colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awNPpOj9CF6O"
      },
      "source": [
        "if colab:\n",
        "    %tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja1-byr4t2NV"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipyd\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.saved_model import signature_constants\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# We'll tell matplotlib to inline any drawn figures like so:\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"\"\"<style> .rendered_html code { \n",
        "    padding: 2px 5px;\n",
        "    color: #0000aa;\n",
        "    background-color: #cccccc;\n",
        "} </style>\"\"\")\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rPsRTmIt2NR"
      },
      "source": [
        "### Download libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVXZj9jAt2NS"
      },
      "source": [
        "if colab:\n",
        "    p = tf.keras.utils.get_file('./material.tgz', 'https://scits-training.unibe.ch/data/tut_files/tpub0320.tgz')\n",
        "    !mv {p} .\n",
        "    !tar -xvzf material.tgz > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgSm_C4zCi_X"
      },
      "source": [
        "from utils import gr_disp\n",
        "from utils import inception"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qclz9zkmqwO"
      },
      "source": [
        "def show_graph(g=None, gd=None):\n",
        "    gr_disp.show_graph_eager(g, gd)\n",
        "    %tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smZh6bC3xSc0"
      },
      "source": [
        "## 2. Convert the Inception model to TF2 format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMM8R_hmIAsw"
      },
      "source": [
        "Let's load the graph definition and inspect the graph\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYV_FP_c7K-x"
      },
      "source": [
        "def load_graph_def(file_path, use_GPU=True):\n",
        "    with tf.compat.v1.gfile.GFile(file_path, \"rb\") as f:\n",
        "        graph_def = tf.compat.v1.GraphDef()\n",
        "        graph_def_str = f.read()\n",
        "        if use_GPU:\n",
        "            graph_def_str = graph_def_str.replace(b'/cpu:0', b'/gpu:0')\n",
        "        graph_def.ParseFromString(graph_def_str)\n",
        "    return graph_def"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMOIIeCg7XOf"
      },
      "source": [
        "gd = load_graph_def('inception/tensorflow_inception_graph.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s2aWXd77b2Z"
      },
      "source": [
        "show_graph(gd=gd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4_XrUcBNL0I"
      },
      "source": [
        "helper function for model conversion:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU03Mm7uxV8_"
      },
      "source": [
        "def convert_model(file_path, save_path, io_tensors, use_GPU=True):\n",
        "    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(save_path)\n",
        "  \n",
        "    graph_def = load_graph_def(file_path, use_GPU)\n",
        "  \n",
        "    sigs = {}\n",
        "  \n",
        "    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n",
        "        # name=\"\" is important to ensure we don't get spurious prefixing\n",
        "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
        "        g = tf.compat.v1.get_default_graph()\n",
        "        inp = g.get_tensor_by_name(io_tensors[0])\n",
        "        out = g.get_tensor_by_name(io_tensors[1])\n",
        "  \n",
        "        sigs[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = \\\n",
        "            tf.compat.v1.saved_model.signature_def_utils.predict_signature_def(\n",
        "                {\"in\": inp}, {\"out\": out})\n",
        "  \n",
        "        builder.add_meta_graph_and_variables(sess,\n",
        "                                            [tag_constants.SERVING],\n",
        "                                            signature_def_map=sigs)\n",
        "  \n",
        "    builder.save()\n",
        "    return graph_def"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD4RPigdxm-X"
      },
      "source": [
        "inc_path = 'inception/tensorflow_inception_graph.pb'\n",
        "inc_path2 = 'inception/saved_tf2'\n",
        "inc_path2_hbn = 'inception/saved_tf2_hbn'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gekUgiOd9n0u"
      },
      "source": [
        "!rm -rf {inc_path2}\n",
        "!rm -rf {inc_path2_hbn}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvL5i77mNZxX"
      },
      "source": [
        "Save model for prediction with specified output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEcetS5Wx5Oy"
      },
      "source": [
        "# set `use_GPU=True` to use GPU acceleration\n",
        "gd_full = convert_model(inc_path, inc_path2, ['input:0', 'output:0'], use_GPU=True)  # original model output\n",
        "gd_hbn = convert_model(inc_path, inc_path2_hbn, ['input:0', 'head0_bottleneck/reshape:0'], use_GPU=True)  # head0_bottleneck as model output, for our problem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRYQPgccNck6"
      },
      "source": [
        "We now can use the model for prediction (similar to what we saw in last session)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRgoasQt8Tnj"
      },
      "source": [
        "mod = tf.saved_model.load('inception/saved_tf2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utpYoF-zNlkX"
      },
      "source": [
        "In a model we can also inspect the graph operations and tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f98v43BJ8WC4"
      },
      "source": [
        "op_names = [op.name for op in mod.graph.get_operations()]\n",
        "#for n in op_names: print(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQp6YjN_Eru"
      },
      "source": [
        "mod.graph.get_tensor_by_name('head0_bottleneck:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAJ6Lsurt2Ne"
      },
      "source": [
        "## 3. Create the graph with regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVU2_Upzsa4a"
      },
      "source": [
        "Here we create a keras layer which processes input with the inception model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi91GM27TYe2"
      },
      "source": [
        "class InceptionCut(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        self.mod = tf.saved_model.load('inception/saved_tf2_hbn')\n",
        "        self.func = self.mod.signatures[\"serving_default\"]\n",
        "        self.output_dim = self.func.outputs[0].shape.as_list()[1]\n",
        "        super(InceptionCut, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(InceptionCut, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.func(x)['out']\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        shape_a = input_shape[0]\n",
        "        return (shape_a[0], self.output_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dka9ZCCsqqI"
      },
      "source": [
        "And build a keras model using it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqAt-68cRlmp"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    InceptionCut(-1),\n",
        "                                    tf.keras.layers.Dense(512, activation='sigmoid'),\n",
        "                                    tf.keras.layers.Dense(2, activation='softmax')\n",
        "                                    ])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0005,) ,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTudmDd5t2Nk"
      },
      "source": [
        "model.build(input_shape=(None,256,256,3))  # neede to initialize model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNbOLvQYt2Nr"
      },
      "source": [
        "## 4. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovWr8fDDt2Ns"
      },
      "source": [
        "The Inception network is trained on natural images: thigs we see around everyday, like sky, flowers, animals, building, cars.\n",
        "It builds an hierarchy of features, to describe what it sees. \n",
        "This features can be used to train fast on different classes of objects. E.g. [here](https://www.tensorflow.org/tutorials/image_retraining) are more examples on transfer learning.\n",
        "\n",
        "Here you will see that these features can be even used to detect thngs very different from natural images. Namely we will try to use it to distinguish German text from Italian. We will use 100 samples, taken from 5 German and 5 Italian books, 10 samples each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc_89xtZt2Ns"
      },
      "source": [
        "text_label = ['German', 'Italian']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOD1q75lt2Nu"
      },
      "source": [
        "labels0 = []\n",
        "images0 = []\n",
        "labels1 = []\n",
        "images1 = []\n",
        "\n",
        "#German\n",
        "for book in range(1,6):\n",
        "    for sample in range(1,11):\n",
        "        img = plt.imread('ML3/de/%d_%d.jpg'%(book, sample))\n",
        "        assert(img.shape[0]>=256 and img.shape[1]>=256 and len(img.shape)==3)\n",
        "        images0.append(inception.prepare_training_img(img))\n",
        "        labels0.append([1,0])\n",
        "for book in range(1,6):\n",
        "    for sample in range(1,11):\n",
        "        img = plt.imread('ML3/it/%d_%d.jpg'%(book, sample))\n",
        "        assert(img.shape[0]>=256 and img.shape[1]>=256 and len(img.shape)==3)\n",
        "        images1.append(inception.prepare_training_img(img))\n",
        "        labels1.append([0,1])\n",
        "        \n",
        "idx = np.random.permutation(len(labels0))\n",
        "labels0 = np.array(labels0)[idx]\n",
        "images0 = np.array(images0)[idx]\n",
        "labels1 = np.array(labels1)[idx]\n",
        "images1 = np.array(images1)[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "85HJPDcAt2Nz",
        "scrolled": false
      },
      "source": [
        "#We will take 80% from each for training and 20 for validation\n",
        "n_half = images0.shape[0]\n",
        "n_train_half = n_half*80//100\n",
        "n_train = n_train_half*2\n",
        "\n",
        "x_train = np.concatenate([images0[:n_train_half], images1[:n_train_half]])\n",
        "y_train = np.concatenate([labels0[:n_train_half], labels1[:n_train_half]])\n",
        "\n",
        "x_valid = np.concatenate([images0[n_train_half:], images1[n_train_half:]])\n",
        "y_valid = np.concatenate([labels0[n_train_half:], labels1[n_train_half:]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2Pf2tEpt2Nw"
      },
      "source": [
        "Lets see a sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUu3dTUXt2Nw"
      },
      "source": [
        "_, axs = plt.subplots(1, 2, figsize=(10,10))\n",
        "img_d = inception.training_img_to_display(images0[25])\n",
        "axs[0].imshow(img_d)\n",
        "axs[0].grid(False)\n",
        "img_d = inception.training_img_to_display(images1[25])\n",
        "axs[1].imshow(img_d)\n",
        "axs[1].grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIQpBhAGO-3O"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apBoSWOOt2Ny"
      },
      "source": [
        "The training is similar to what we we saw previously.\n",
        "\n",
        "Since Inception model is big, this will take a while, even we use GPUs (one T4 / 2 users). On your laptop CPU this would probably take ~15 times longer. And we are not training the whole Inception! We have just small thing on top + a very small dataset!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibxBnLALPNn_"
      },
      "source": [
        "We will use callback to save checkpoints on each iteration of training. They contain values of trainable variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6TwMc5jaU-P",
        "scrolled": true
      },
      "source": [
        "save_path = 'save/text_{epoch}.ckpt'\n",
        "\n",
        "batch_size=10\n",
        "n_itr_per_epoch = len(x_train) // batch_size\n",
        "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_path,\n",
        "                                                   save_weights_only=True,\n",
        "                                                   save_freq=5 * n_itr_per_epoch) # save every 5 epochs\n",
        "\n",
        "hist = model.fit(x_train, y_train,\n",
        "                 epochs=150, batch_size=batch_size, \n",
        "                 validation_data=(x_valid, y_valid),\n",
        "                 callbacks=[save_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU6aG1zlaVcA"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "axs[0].plot(hist.epoch, hist.history['loss'])\n",
        "axs[0].plot(hist.epoch, hist.history['val_loss'])\n",
        "axs[0].legend(('training loss', 'validation loss'), loc='lower right')\n",
        "axs[1].plot(hist.epoch, hist.history['accuracy'])\n",
        "axs[1].plot(hist.epoch, hist.history['val_accuracy'])\n",
        "\n",
        "axs[1].legend(('training accuracy', 'validation accuracy'), loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr5x3x2at2N0"
      },
      "source": [
        "We see that training accuracy hits 100% quickly. Why do you think it happens? Consider that loss keeps decreasing.\n",
        "Also on such a small dataset our model overfits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwH_H7b6t2N1"
      },
      "source": [
        "## 6. Load trained variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrtttZKEt2N1"
      },
      "source": [
        "If we have the model already created we can easily load the saved training variables values from a checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uc8TW0vt2N2"
      },
      "source": [
        "#in the beginning:\n",
        "model.load_weights('save/text_5.ckpt')\n",
        "model.evaluate(images1[:1],  labels1[:1], verbose=2)\n",
        "\n",
        "#in the end:\n",
        "model.load_weights('save/text_150.ckpt')\n",
        "model.evaluate(images1[:1],  labels1[:1], verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh0y_Hr4t2N5"
      },
      "source": [
        "## 7. Saving for inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24LEtunzQGMf"
      },
      "source": [
        "In tf2 it's easy to save a model for inference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKSZz5Jnt2OK"
      },
      "source": [
        "tf.saved_model.save(model, \"inference_model/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rc9mTd-t2OM"
      },
      "source": [
        "## 8. Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJIgyaB7t2ON"
      },
      "source": [
        "mod = tf.saved_model.load('inference_model')\n",
        "func = mod.signatures[\"serving_default\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-qCAKnEd2p6"
      },
      "source": [
        "output_name = model.output_names[0]  # single output\n",
        "print(output_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu7AI5U4t2OP"
      },
      "source": [
        "res = func(tf.constant(images1[:1]))[output_name]\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZMfDpJwiPD0"
      },
      "source": [
        "Or we can make a nice wrapper:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "XmDxdQoDeUey"
      },
      "source": [
        "class Inferer:\n",
        "    def __init__(self, model_path, output_name):\n",
        "        self.mod = tf.saved_model.load(model_path)\n",
        "        self.func = self.mod.signatures[\"serving_default\"]\n",
        "        self.output_name = output_name\n",
        "        self.class_names = np.array(['german', 'italian'])\n",
        "        self.max_len = 64\n",
        "\n",
        "    def infere_class_batch(self, inputs):\n",
        "        probabilities = self.func(tf.constant(inputs))[self.output_name].numpy()\n",
        "        classes = np.argmax(probabilities, axis=1)\n",
        "        probs = probabilities[np.arange(len(classes)), classes]\n",
        "        return classes, probs\n",
        "\n",
        "    def infere_class(self, inputs):\n",
        "        n = len(inputs)\n",
        "        if n > self.max_len:\n",
        "            classes = []\n",
        "            probs = []\n",
        "            for i in range( (n+self.max_len-1) // self.max_len):\n",
        "                batch = inputs[i* self.max_len : (i+1)* self.max_len]\n",
        "                batch_classes, batch_probs = self.infere_class_batch(batch)\n",
        "                classes.append(batch_classes)\n",
        "                probs.append(batch_probs)\n",
        "            classes = np.concatenate(classes)\n",
        "            probs = np.concatenate(probs)\n",
        "        else:\n",
        "            classes, probs = self.infere_class_batch(inputs)\n",
        "  \n",
        "        return classes, probs\n",
        "\n",
        "    def infere(self, inputs, prob=False):\n",
        "        classes, probs = self.infere_class(inputs)\n",
        "        cn = self.class_names[classes]\n",
        "        return (cn, probs) if prob else cn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZVASuj1jYLx"
      },
      "source": [
        "inf = Inferer('inference_model', output_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJSEv3ctfmwy"
      },
      "source": [
        "inf.infere(images0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpLPDU87lBMp"
      },
      "source": [
        "images_all = np.concatenate([images0, images1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOqCpeZ4fyTh"
      },
      "source": [
        "inf.infere(images_all, prob=True) # ouput class confidence probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K71p8F0t2OS"
      },
      "source": [
        "## 9. Improving the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwVcKUelt2OU"
      },
      "source": [
        "Often, as in this sample we don't have anough labeled data in hand. We need to use it as efficient as possible.\n",
        "One way to do it is to aply training data augmentation: we can slightly distort it, e.g. rescale, to effectively multiply the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoER6gFgt2OV"
      },
      "source": [
        "We will generate rescaled images, minimum - to have smaller dimension equal 256, maximum - 130%. Let's define a function which will do this job:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBX83LXot2OV"
      },
      "source": [
        "def get_random_scaled_img(file, minsize = 256, scalemax=1.3):\n",
        "    im = Image.open(file)\n",
        "    w, h = im.size\n",
        "    # get minimal possible size\n",
        "    scalemin =float(minsize) / min(w,h)\n",
        "    # get a rescale factor from a uniform distribution.\n",
        "    scale = scalemin + np.random.rand() * (scalemax - scalemin)\n",
        "    w1 = int(max(minsize, scale*w))\n",
        "    h1 = int(max(minsize, scale*h))\n",
        "    \n",
        "    #rescale with smoothing\n",
        "    im1 = im.resize((w1,h1), Image.ANTIALIAS)\n",
        "    #get numpy array from the PIL Image\n",
        "    img_arr = np.array(im1.convert('RGB'))\n",
        "\n",
        "    #crop to 256x256, preventing further resize by prepare_training_img\n",
        "    r = (img_arr.shape[0] - minsize) // 2\n",
        "    c = (img_arr.shape[1] - minsize) // 2\n",
        "    img_arr = img_arr[r:r+minsize,c:c+minsize]\n",
        "\n",
        "    return img_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL8Qt87it2OX"
      },
      "source": [
        "Lets check rescaled images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C4aL8x_t2OX"
      },
      "source": [
        "n_smpl=2\n",
        "scaled_imgs=[get_random_scaled_img('ML3/de/%d_%d.jpg'%(1, 1)) for i in range(n_smpl**2)]\n",
        "fig, ax = plt.subplots(n_smpl, n_smpl, figsize=(n_smpl*4, n_smpl*4))\n",
        "for row in range(n_smpl):\n",
        "    for col in range(n_smpl):\n",
        "        ax[col, row].imshow(scaled_imgs[row*n_smpl+col])\n",
        "        ax[col, row].grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kisfRq3vt2OZ"
      },
      "source": [
        "Read again images, now generating 5 rescaled from each one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3DtE8hQt2OZ"
      },
      "source": [
        "labels0 = []\n",
        "images0 = []\n",
        "labels1 = []\n",
        "images1 = []\n",
        "\n",
        "mult = 5\n",
        "#German\n",
        "for book in range(1,6):\n",
        "    for sample in range(1,11):\n",
        "        for itr in range(mult):\n",
        "            img = get_random_scaled_img('ML3/de/%d_%d.jpg'%(book, sample))\n",
        "            assert(img.shape[0]>=256 and img.shape[1]>=256 and len(img.shape)==3)\n",
        "            images0.append(inception.prepare_training_img(img))\n",
        "            labels0.append([1,0])\n",
        "#Italian\n",
        "for book in range(1,6):\n",
        "    for sample in range(1,11):\n",
        "        for itr in range(mult):\n",
        "            img = get_random_scaled_img('ML3/it/%d_%d.jpg'%(book, sample))\n",
        "            assert(img.shape[0]>=256 and img.shape[1]>=256 and len(img.shape)==3)\n",
        "            images1.append(inception.prepare_training_img(img))\n",
        "            labels1.append([0,1])\n",
        "        \n",
        "idx = np.random.permutation(len(labels0))\n",
        "labels0 = np.array(labels0)[idx]\n",
        "images0 = np.array(images0)[idx]\n",
        "labels1 = np.array(labels1)[idx]\n",
        "images1 = np.array(images1)[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPTso1cft2Ob"
      },
      "source": [
        "#We will take 80% from each for training and 20 for validation\n",
        "n_half = images0.shape[0]\n",
        "n_train_half = n_half*80//100\n",
        "n_train = n_train_half*2\n",
        "\n",
        "x_train = np.concatenate([images0[:n_train_half], images1[:n_train_half]])\n",
        "y_train = np.concatenate([labels0[:n_train_half], labels1[:n_train_half]])\n",
        "\n",
        "x_valid = np.concatenate([images0[n_train_half:], images1[n_train_half:]])\n",
        "y_valid = np.concatenate([labels0[n_train_half:], labels1[n_train_half:]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeDPdwjHt2Ob"
      },
      "source": [
        "And finally do training again, same way. Just now we change the number of epochs: before we had 150, but now that we have 5 times more training data we'll do 60. While 60 > 150/5, it looks like it takes a bit more time to converge.\n",
        "We use the same graph as before, `g2`, the one we can train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzum4jNQRhHB"
      },
      "source": [
        "#We will take 80% from each for training and 20 for validation\n",
        "n_half = images0.shape[0]\n",
        "n_train_half = n_half*80//100\n",
        "n_train = n_train_half*2\n",
        "\n",
        "x_train = np.concatenate([images0[:n_train_half], images1[:n_train_half]])\n",
        "y_train = np.concatenate([labels0[:n_train_half], labels1[:n_train_half]])\n",
        "\n",
        "x_valid = np.concatenate([images0[n_train_half:], images1[n_train_half:]])\n",
        "y_valid = np.concatenate([labels0[n_train_half:], labels1[n_train_half:]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s2lS9FLZHqw"
      },
      "source": [
        "model_aug = tf.keras.models.Sequential([\n",
        "                                    InceptionCut(-1),\n",
        "                                    tf.keras.layers.Dense(512, activation='sigmoid'),\n",
        "                                    tf.keras.layers.Dense(2, activation='softmax')\n",
        "                                    ])\n",
        "\n",
        "model_aug.compile(optimizer=tf.keras.optimizers.Adam(0.0005,) ,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX8D7NZ7lsEl"
      },
      "source": [
        "save_path = 'save/text_augmented_{epoch}.ckpt'\n",
        "\n",
        "batch_size=10\n",
        "n_itr_per_epoch = len(x_train) // batch_size\n",
        "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_path,\n",
        "                                                   save_weights_only=True,\n",
        "                                                   save_freq=5 * n_itr_per_epoch) # save every 5 epochs\n",
        "                                                   \n",
        "hist = model_aug.fit(x_train, y_train,\n",
        "                 epochs=60, batch_size=batch_size, \n",
        "                 validation_data=(x_valid, y_valid),\n",
        "                 callbacks=[save_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJlKctX6l32R"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "axs[0].plot(hist.epoch, hist.history['loss'])\n",
        "axs[0].plot(hist.epoch, hist.history['val_loss'])\n",
        "axs[0].legend(('training loss', 'validation loss'), loc='lower right')\n",
        "axs[1].plot(hist.epoch, hist.history['accuracy'])\n",
        "axs[1].plot(hist.epoch, hist.history['val_accuracy'])\n",
        "\n",
        "axs[1].legend(('training accuracy', 'validation accuracy'), loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsLty-0Rl_u1"
      },
      "source": [
        "tf.saved_model.save(model_aug, \"inference_model_aug/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHZx8jQot2Oc"
      },
      "source": [
        "We had a REEEALLY small dataset for such a complicated task. Does it really generalize? mb it just memorizes all the images we fed into it? Lets perform a test. `w1.PNG` and `w2.PNG` are text screenshots from wikipedia in [Italian](https://it.wikipedia.org/wiki/Apprendimento_automatico) and [German](https://de.wikipedia.org/wiki/Maschinelles_Lernen)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbAqHCWt2Od"
      },
      "source": [
        "# load images\n",
        "im_wiki_1 = plt.imread('ML3/w1.jpg')\n",
        "im_wiki_2 = plt.imread('ML3/w2.jpg')\n",
        "\n",
        "# crop/covert for proper color range\n",
        "im_wiki_1_p = inception.prepare_training_img(im_wiki_1)[np.newaxis]\n",
        "im_wiki_2_p = inception.prepare_training_img(im_wiki_2)[np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T6yv7z8mPc-"
      },
      "source": [
        "output_name = model_aug.output_names[0]\r\n",
        "inf = Inferer('inference_model_aug', output_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCXZInp8mPdC"
      },
      "source": [
        "class_name, prob = inf.infere(np.concatenate([im_wiki_1_p, im_wiki_2_p]), prob=True)\n",
        "\n",
        "\n",
        "print('probabilities for w1:', prob[0], 'detected language:', class_name[0])\n",
        "print('probabilities for w2:', prob[1], 'detected language:', class_name[1])\n",
        "\n",
        "# Show image crops\n",
        "plt.imshow( inception.training_img_to_display(im_wiki_1_p[0]))\n",
        "plt.show()\n",
        "plt.imshow( inception.training_img_to_display(im_wiki_2_p[0]))\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN0LvX7dt2Of"
      },
      "source": [
        "## 12. Excercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGzj4VPFt2Og"
      },
      "source": [
        "There is a serious problem in the example above: the training and validation datasets are not independent. We generated 5 randomly scaled images from each initial image. With high probability from 5 images (generated from same initial one!) some will end up im the training and some in validation datasets. Since they are generated from the same initial ones, they are not fully independent. This compromises evaluation of model performance, leading to an overestimate of the performance.\n",
        "\n",
        "1. Modify the generation of the training and validation datasets to fulfil requirenment of independance.\n",
        "2. Check how validation accuracy and loss changes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj0ra0Cpt2Og"
      },
      "source": [
        "## 13. Excercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSMxY4ezt2Oh"
      },
      "source": [
        "(Hope we have time left....)\n",
        "Test the performance of model trained on NOT rescaled images, on the wiki screenshots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoFMTLTQt2Oi"
      },
      "source": [
        "# copy the above code here\n",
        "# load the original model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u0_qadxt2Ok"
      },
      "source": [
        "## 14. Homework (3 options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5x83mdht2Ol"
      },
      "source": [
        "### 14.1 Improve training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SetU7UKt2Ol"
      },
      "source": [
        "So far we scaled images as a whole. \n",
        "- Try to scale differently in $x$ and $y$ direction.\n",
        "- Check how it affects performace.\n",
        "- Which else transformation would make sence for the text data?\n",
        "- Get hands dirty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxfnvGort2Om"
      },
      "source": [
        "### 14.2 Try to use lower layers' outputs from Inception to build the classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn0H865Xt2On"
      },
      "source": [
        "So far we used last output of Inception.\n",
        "- Look at the Inception more carefully.\n",
        "- Inspect the size of the data array at different layers.\n",
        "- Since inside you have 3D data (2D image * features at each position) you will need to flatten it. Look how this is done in last layers (`head0`). Alternatively you can create convolutional layers.\n",
        "- Ask, google it, and get your hands dirty!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwcVPGjtt2Oo"
      },
      "source": [
        "### 14.3 Classify 3 languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQl062yyt2Oo"
      },
      "source": [
        "So far we tried two languages.\n",
        "- Create 50 crops of text in another language (better use 5 sources with different fonts, otherwise you risk to learn font, not language), images size > 300 x 300 (to allow scaling).\n",
        "- Upload them to the `ML3` directory inside of a new directory `xx`.\n",
        "- Repeat everything with 3 classes.\n",
        "- Think of the case when this approach won't work.\n",
        "- Get hands dirty!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azGK6ie4Q05I"
      },
      "source": [
        "## 15. Solution to exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwUWaKdeRhHe"
      },
      "source": [
        "To prevent same rescaled versions of the same image ending up in both training and validation sets, we could split the dataset first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPBjfz05RhHe"
      },
      "source": [
        "# list all samples\n",
        "de_book_sample = [(book, sample) for book in range(1,6) for sample in range(1,11)]\n",
        "it_book_sample = [(book, sample) for book in range(1,6) for sample in range(1,11)]\n",
        "\n",
        "de_book_sample = np.array(de_book_sample)\n",
        "it_book_sample = np.array(it_book_sample)\n",
        "\n",
        "# get array of permultation indexes\n",
        "n_half = len(de_book_sample)  # size of both datasets is identical\n",
        "de_idx = np.random.permutation(n_half)\n",
        "it_idx = np.random.permutation(n_half)\n",
        "\n",
        "# shuffle list of samples\n",
        "de_book_sample = de_book_sample[de_idx]\n",
        "it_book_sample = it_book_sample[it_idx]\n",
        "\n",
        "# split training and validation\n",
        "# We will take 80% from each for training and 20 for validation\n",
        "n_train_half = n_half*80//100\n",
        "n_train = n_train_half*2\n",
        "\n",
        "de_book_sample_train = de_book_sample[:n_train_half] # first 80 %\n",
        "de_book_sample_valid = de_book_sample[n_train_half:] # remaining part\n",
        "\n",
        "it_book_sample_train = it_book_sample[:n_train_half] # first 80 %\n",
        "it_book_sample_valid = it_book_sample[n_train_half:] # remaining part\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "x_valid = []\n",
        "y_valid = []\n",
        "\n",
        "mult = 5\n",
        "for itr in range(mult):\n",
        "    # each pair [book,sample] goes to either training or validation set, not both\n",
        "    # German training\n",
        "    for book, sample in de_book_sample_train:\n",
        "        img = get_random_scaled_img('ML3/de/%d_%d.jpg'%(book, sample), scalemax=1.5)\n",
        "        assert(img.shape[0]>=256 and img.shape[1]>=256 and len(img.shape)==3)\n",
        "        x_train.append(inception.prepare_training_img(img))\n",
        "        y_train.append([1,0])\n",
        "  \n",
        "    # Italian training\n",
        "    for book, sample in it_book_sample_train:\n",
        "        img = get_random_scaled_img('ML3/it/%d_%d.jpg'%(book, sample), scalemax=1.5)\n",
        "        assert(img.shape[0]>=256 and img.shape[1]>=256 and len(img.shape)==3)\n",
        "        x_train.append(inception.prepare_training_img(img))\n",
        "        y_train.append([0,1])\n",
        "  \n",
        "    # German validation\n",
        "    for book, sample in de_book_sample_valid:\n",
        "        img = get_random_scaled_img('ML3/de/%d_%d.jpg'%(book, sample), scalemax=1.5)\n",
        "        assert(img.shape[0]>=256 and img.shape[1]>=256 and len(img.shape)==3)\n",
        "        x_valid.append(inception.prepare_training_img(img))\n",
        "        y_valid.append([1,0])\n",
        "  \n",
        "    # Italian validation\n",
        "    for book, sample in it_book_sample_valid:\n",
        "        img = get_random_scaled_img('ML3/it/%d_%d.jpg'%(book, sample), scalemax=1.5)\n",
        "        assert(img.shape[0]>=256 and img.shape[1]>=256 and len(img.shape)==3)\n",
        "        x_valid.append(inception.prepare_training_img(img))\n",
        "        y_valid.append([0,1])\n",
        "\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_valid = np.array(x_valid)\n",
        "y_valid = np.array(y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}