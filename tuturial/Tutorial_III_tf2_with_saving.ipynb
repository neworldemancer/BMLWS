{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Tutorial_III_tf2_with_saving.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxDZW841tkSi"
      },
      "source": [
        "# Tutorial III: Handwritten digit recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nha4NG_tkSl"
      },
      "source": [
        "<p>\n",
        "Bern Winter School on Machine Learning, 2021<br>\n",
        "Prepared by Mykhailo Vladymyrov.\n",
        "</p>\n",
        "\n",
        "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjuW0SKStkSm"
      },
      "source": [
        "This is a supplementary material describing the fully-connected neural network for handwritten digit recognition using TensorFlow 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dit404ghtkSr"
      },
      "source": [
        "## 1. Load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fcfiHcmuAPA"
      },
      "source": [
        "colab = True # set to True is using google colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kJz7FwGYUOh"
      },
      "source": [
        "if colab:\r\n",
        "    %tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbRY_dIutkSr"
      },
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipyd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.datasets.mnist as mnist\n",
        "\n",
        "# We'll tell matplotlib to inline any drawn figures like so:\n",
        "#%matplotlib inline\n",
        "#plt.style.use('ggplot')\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"\"\"<style> .rendered_html code { \n",
        "    padding: 2px 5px;\n",
        "    color: #0000aa;\n",
        "    background-color: #cccccc;\n",
        "} </style>\"\"\")\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcuT4JYRtkS4"
      },
      "source": [
        "## 1. Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrbUAUlrtkS4"
      },
      "source": [
        "First we will load the data: 60000 training images and 10000 images for validation. We will keep the images 2D and slatten them directly in the model.\n",
        "\n",
        "We will as well keep the labels as class ID, intead of the one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L33vRL03tkS7"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "\n",
        "print ('train: data shape', x_train.shape, 'label shape', y_train.shape)\n",
        "print ('test: data shape', x_test.shape, 'label shape', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agJ3gkg0tkTJ"
      },
      "source": [
        "## 2. Bulding a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPs6sljtjDUE"
      },
      "source": [
        "The following creates a 'model'. It is an object containing the ML model itself - a simple 3-layer fully connected neural network, optimization parameters, as well as tha interface for model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC1SpGLbtkTL",
        "cellView": "code"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(1500, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.005) ,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFwr5MLMjxI1"
      },
      "source": [
        "Model summary provides information about the model's layers and trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCttp5zeb5l2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P18eyAQHqZGG"
      },
      "source": [
        "## 3. Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIdb5Gtlr32"
      },
      "source": [
        "The `fit` function is the interface for model training. \n",
        "Here one can specify training and validation datasets, minibatch size, and the number of training epochs.\n",
        "\n",
        "**Warining**: call to `model.fit` does NOT reinitialize trainable variables. Every time it continues from the previous state.\n",
        "\n",
        "We will also save the state of the trainable variables after each epoch: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71zJQIiZ6btk"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-OxT0aNVx-y"
      },
      "source": [
        "save_path = 'save/mnist_{epoch}.ckpt'\n",
        "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, save_weights_only=True)\n",
        "\n",
        "logdir=\"logs/\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "hist = model.fit(x=x_train, y=y_train,\n",
        "                 epochs=25, batch_size=128, \n",
        "                 validation_data=(x_test, y_test),\n",
        "                 callbacks=[save_callback, tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l9Gz1e4V-7Q"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "axs[0].plot(hist.epoch, hist.history['loss'])\n",
        "axs[0].plot(hist.epoch, hist.history['val_loss'])\n",
        "axs[0].legend(('training loss', 'validation loss'), loc='lower right')\n",
        "axs[1].plot(hist.epoch, hist.history['accuracy'])\n",
        "axs[1].plot(hist.epoch, hist.history['val_accuracy'])\n",
        "\n",
        "axs[1].legend(('training accuracy', 'validation accuracy'), loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUnlYrfaBmQ8"
      },
      "source": [
        "Current model performance can be evaluated on a dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cq_gqG4V9il"
      },
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-5qgb0rDyj4"
      },
      "source": [
        "We cat test trained model on a image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPU8mOg2DVSO"
      },
      "source": [
        "im_id = 0\n",
        "y_pred = model(x_test[im_id:im_id+1])\n",
        "print('true lablel: ', y_test[im_id], 'predicted: ', np.argmax(y_pred[0]) )\n",
        "plt.imshow(x_test[im_id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkrIXxYmqiyR"
      },
      "source": [
        "## 4. Loading trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt_BelVEdH1y"
      },
      "source": [
        "model.load_weights('save/mnist_1.ckpt')\n",
        "model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "model.load_weights('save/mnist_12.ckpt')\n",
        "model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "model.load_weights('save/mnist_18.ckpt')\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxIIoNRYqqd_"
      },
      "source": [
        "## 5. Inspecting trained variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5waklWBUBwuO"
      },
      "source": [
        "We can obtain the trained variables from model layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-nnCph8rU01"
      },
      "source": [
        "l = model.get_layer(index=1)\n",
        "w, b = l.weights\n",
        "\n",
        "w = w.numpy()\n",
        "b = b.numpy()\n",
        "print(w.shape, b.shape)\n",
        "w = w.reshape((28,28,-1)).transpose((2, 0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfmd5YeUCCKO"
      },
      "source": [
        "Let's visualize first 5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8UOgBWJfzMg"
      },
      "source": [
        "n = 5\n",
        "fig, axs = plt.subplots(1, n, figsize=(4.1*n,4))\n",
        "for i, wi in enumerate(w[:5]):\n",
        "  axs[i].imshow(wi, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i02IbJ2gtkTT"
      },
      "source": [
        "## 6. Inspecting gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uuktPZ9CX8W"
      },
      "source": [
        "We can also evaluate the gradients of each output with respect to an input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L371n9COtkTU"
      },
      "source": [
        "idx = 111\n",
        "inp_v = x_train[idx:idx+1]  # use some image to compute gradients with respect to\n",
        "\n",
        "inp = tf.constant(inp_v)  # create tf constant tensor\n",
        "with tf.GradientTape() as tape:  # gradient tape for gradint evaluation\n",
        "  tape.watch(inp)  # take inp as variable\n",
        "  preds = model(inp) # evaluate model output\n",
        "\n",
        "grads = tape.jacobian(preds, inp)  # evaluate d preds[i] / d inp[j]\n",
        "print(grads.shape, '<- (Batch_preds, preds[i], Batch_inp, inp[y], inp[x])')\n",
        "grads = grads.numpy()[0,:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83mY_1BKiIIB"
      },
      "source": [
        "print('prediction:', np.argmax(preds[0]))\n",
        "fig, axs = plt.subplots(1, 11, figsize=(4.1*11,4))\n",
        "axs[0].imshow(inp_v[0])\n",
        "axs[0].set_title('raw')\n",
        "vmin,vmax = grads.min(), grads.max()\n",
        "for i, g in enumerate(grads):\n",
        "  axs[i+1].imshow(g, cmap='gray', vmin=vmin, vmax=vmax)\n",
        "  axs[i+1].set_title(r'$\\frac{\\partial\\;P(digit\\,%d)}{\\partial\\;input}$' % i, fontdict={'size':16})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmUMxBEO9tck"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}