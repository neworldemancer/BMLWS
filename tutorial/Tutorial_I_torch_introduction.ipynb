{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMGVjU25TLzx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial I: Introduction to PyTorch (torch)\n",
        "<p>\n",
        "Bern Winter School on Machine Learning, 2024<br>\n",
        "Prepared by Mykhailo Vladymyrov and Matthew Vowels.\n",
        "</p>\n",
        "\n",
        "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
        "\n",
        "In this tutorial session we will get familiar wtih:\n",
        "* How to do optimization in torch and what possibilities does that open to data science\n",
        "* how to apply that to virtually any practical problem\n",
        "   * unordered/tabular data\n",
        "   * data with continuous dimensions\n",
        "   * sequential data\n",
        "\n",
        "\n",
        "\n",
        "torch provides a high-level interface, allowing easy implementation.\n",
        "\n",
        "While it is easy to use, some fundamental conceps can remain a bit obscured, but we will try to clarify that in the course."
      ],
      "metadata": {
        "id": "gg8g6scvTgnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00. Requirements\n",
        "\n",
        "To run this notebooks you need torch and numpy installed.\n",
        "As some parts of this tutorial rely on specific functions, it's strongly advised to use the Chrome browser or Chromium derivatives.\n",
        "\n",
        "Basic knowledge of Python can be acquired [here](https://docs.python.org/3/tutorial/) and of Numpy [here](https://docs.scipy.org/doc/numpy/user/quickstart.html)\n",
        "\n",
        "Full documentation on torch functions is available in the [reference](https://pytorch.org/docs/stable/index.html).\n"
      ],
      "metadata": {
        "id": "fALIgdeITg55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Cell execution\n",
        "\n",
        "> Indented block\n",
        "Press ``Ctrl+Enter`` or ``Shift+Enter`` on the next cell to execute the content\n"
      ],
      "metadata": {
        "id": "87oX-c-FTg_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('It works!')"
      ],
      "metadata": {
        "id": "xlblJm2DUL7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navigate between cells with arrows. Press `Enter` to edit cell, `Esc` to exit."
      ],
      "metadata": {
        "id": "ASNnoSiUURJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load necessary libraries"
      ],
      "metadata": {
        "id": "XMZ1Z7s-UaxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "rE6mOT8aUR6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download libraries"
      ],
      "metadata": {
        "id": "JmER6N64ZUZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# URL of the file to download\n",
        "url = 'https://github.com/neworldemancer/BMLWS/raw/main/tut_files/tpub0320.tgz'\n",
        "\n",
        "# Path where the file will be saved\n",
        "path = os.path.abspath('.') + '/material.tgz'\n",
        "\n",
        "# Download the file\n",
        "response = requests.get(url)\n",
        "assert response.status_code == 200, \"Download failed\"\n",
        "with open(path, 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Check if the path is correct\n",
        "assert os.path.exists(path), \"File not found\"\n",
        "\n",
        "# Extract the tar file\n",
        "tar = tarfile.open(path, \"r:gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "metadata": {
        "id": "Sl58R8WeUf0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create our first model\n",
        "\n",
        "First we need to define the input for the model. We will create `Input`, where during the excecution we will feed in the input values."
      ],
      "metadata": {
        "id": "5p2LCP4zaAgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = x + 2\n",
        "        return x * out1\n",
        "\n",
        "# Create an instance of the model\n",
        "model = SimpleModel()\n",
        "\n",
        "# Example of using the model with dummy input\n",
        "input_tensor = torch.tensor(1.0)  # Example input\n",
        "output = model(input_tensor)\n"
      ],
      "metadata": {
        "id": "RjEsEDZbZV5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rgLCYhrCosL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Run the model\n"
      ],
      "metadata": {
        "id": "CnRft8Fga541"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_res = model(torch.tensor(5.0))\n",
        "print(out_res)\n"
      ],
      "metadata": {
        "id": "Xt-3tKzca-3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(out_res)"
      ],
      "metadata": {
        "id": "RPJf5StypN8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Several values can be computed at the same time:"
      ],
      "metadata": {
        "id": "hsenbNgdbDnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_val = model(torch.tensor([1, 2, 1]))\n",
        "print(out_val)"
      ],
      "metadata": {
        "id": "Ta6YZSpcaa91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Tensor operations\n",
        "\n",
        "For ML tasks we often need to perform operations on high-dimensional data. Theese are represented as tensors in torch. For example we can calculate sum of squared values in an 1D array with 5 elements:"
      ],
      "metadata": {
        "id": "dmSH2VjZbeP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel2, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = x + 2\n",
        "        return torch.sum(out1)\n",
        "\n",
        "\n",
        "model2 = SimpleModel2()\n",
        "out_val = model2(torch.tensor([1, 2, 1]))\n",
        "print(out_val)"
      ],
      "metadata": {
        "id": "9tjrpbLwaoA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or we can do the same for several 1D arrays at once:"
      ],
      "metadata": {
        "id": "sfMe-WehcGVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel3, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = x + 2\n",
        "        return torch.sum(out1, axis=1)\n",
        "\n",
        "\n",
        "model3 = SimpleModel3()\n",
        "array = torch.tensor([[1,2,1],[1,2,1],[2,1,2],[2,1,2]])\n",
        "print('input shape:', array.shape)\n",
        "\n",
        "out_vals = model3(array)\n",
        "print('output shape:', out_vals.shape)\n",
        "print('output:', out_vals)"
      ],
      "metadata": {
        "id": "JGb9Zinwb1jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Exercise 1"
      ],
      "metadata": {
        "id": "IaFgi162c9_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum?"
      ],
      "metadata": {
        "id": "6lXaa1iocdgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the code bellow to calculate mean of array's elements."
      ],
      "metadata": {
        "id": "OrAi5OOCdGn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MeanModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MeanModel, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return  ???\n",
        "\n",
        "# define data:\n",
        "arr = torch.tensor([[1,2,3,4,5], [2,3,4,5.1,6], [25,65,12,12,11]])\n",
        "\n",
        "model = ???  # define model\n",
        "result = ???  # run model\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "pQSZfDxZdEOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Optimization problem\n",
        "\n",
        "In ML we always try to optimize model parameters to minimize a loss function. pytorch provides easy interface for solving optimization problems.\n",
        "\n",
        "Let's see how this works. We will use a function $f$, parabolic with respect to the model parameter $t$: $f(x_0, x_1|t) = (x_0*t-x_1)^2$. Here $x_0$ and $x_1$ are given values for which we will try to minimize value of function $f$ by modifying $t$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eM1uPaXbds4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FLayer, self).__init__()\n",
        "        self.t = nn.Parameter(torch.tensor(0.0))  # Initializing as a learnable parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = x[..., 0]   # the ellipsis here selects all previous dimensions as they are, and the last as dim 0\n",
        "        x1 = x[..., 1]   # the ellipsis here selects all previous dimensions as they are, and the last as dim 1\n",
        "        return (x0 * self.t - x1) ** 2\n",
        "\n",
        "        # df/dt = 2 * (x0 * self.t - x1) * x0"
      ],
      "metadata": {
        "id": "TQWFqxPidcT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simplicity we will keep $x_0$ and $x_1$ in an array: `x` = [$x_0$, $x_1$]"
      ],
      "metadata": {
        "id": "N802UDEleIoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FLayer()"
      ],
      "metadata": {
        "id": "-XEnxV0keJIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we create an optimizer: object that on each iteration adjusts values of all trainable parameters (in our case just `t` to minimize the value of `f`.\n",
        "Here we will use plain steepest gradient descent.\n",
        "\n",
        "We will minimize the value of the models output."
      ],
      "metadata": {
        "id": "UP0wnuYsfmYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for p in model.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "id": "oDEtEb4M0GMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FLayer()\n",
        "\n",
        "# Optimizer (e.g., SGD or Adam)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Values of x0 and x1 for which we will minimize f\n",
        "x0_val = 3.\n",
        "x1_val = 9.\n",
        "\n",
        "x0_t = torch.tensor([x0_val])\n",
        "x1_t = torch.tensor([x1_val])\n",
        "x_val = torch.stack([x0_t, x1_t], dim=-1)\n",
        "\n",
        "#print(x_val.shape)\n",
        "\n",
        "# Buffers to store intermediate values of t and f to plot them later\n",
        "t_sv = []\n",
        "f_sv = []\n",
        "\n",
        "\n",
        "# Initial evaluation\n",
        "with torch.no_grad():\n",
        "    f_val = model(x_val)\n",
        "    t_val = model.t\n",
        "\n",
        "t_sv.append(t_val.item())\n",
        "f_sv.append(f_val.item())\n",
        "\n",
        "# Optimization loop\n",
        "for itr in range(30):\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    f_val = model(x_val)  # Forward pass\n",
        "    loss = f_val  # Your loss function seems to just return the model output\n",
        "    loss.backward()  # Compute gradients\n",
        "    optimizer.step()  # Update parameters\n",
        "\n",
        "    # Logging current values of t and f\n",
        "    with torch.no_grad():\n",
        "        f_val = model(x_val)\n",
        "        t_val = model.t\n",
        "\n",
        "    t_sv.append(t_val.item())\n",
        "    f_sv.append(f_val.item())"
      ],
      "metadata": {
        "id": "07BKIbDYfl6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just find the nice range for plotting\n",
        "x0 = x1_val/x0_val\n",
        "xhalf = max(abs(t_sv[0]-x0), 5.)\n",
        "#fill array for parabola\n",
        "t_all = np.arange(x0-xhalf, x0+xhalf, xhalf/50.)\n",
        "f_all = np.asarray([(ti*x0_val-x1_val)*(ti*x0_val-x1_val) for ti in t_all])\n",
        "\n",
        "#draw all\n",
        "_, axs = plt.subplots(1, 3, figsize=(16,10))\n",
        "axs[0].plot(t_all, f_all, 'b', alpha=0.3)\n",
        "axs[0].plot(t_sv, f_sv, 'g^')  # -> 'g^--'\n",
        "axs[0].set_title('f(t | x1,x2)')\n",
        "axs[0].set_xlabel('t')\n",
        "axs[0].set_ylabel('f(t)')\n",
        "axs[0].legend(('f(t)', 'training iterations'),  loc='upper center')\n",
        "axs[1].plot(f_sv, '.-')\n",
        "axs[1].set_title('f(itr)');\n",
        "axs[1].set_ylabel('f(t)')\n",
        "axs[1].set_xlabel('training iteration')\n",
        "axs[2].plot(t_sv, '.-')\n",
        "axs[2].set_title('t(itr)');\n",
        "axs[2].set_ylabel('t(itr)')\n",
        "axs[2].set_xlabel('training iteration')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YaOVgz-4f8iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, in the example above, we can compute the solution analytically for $(x0∗t−x1)^2$. Rewriting it for convenience as $y=(ax+b)^2 = a^2x^2 + 2abx +b^2$, we can derive the gradient $\\frac{dy}{dx} = 2a^2x + 2ab$. This can be evaluated for $\\frac{dy}{dx} =0$ with the values of $a=3$ and $b=-9$: $18x = 54$ so $x=3$. This confirms that our optimization process converged to the correct (analytic) solution.\n",
        "\n",
        "In practice, the functions will not be simple, and for sure the derivation of an analytic solution will not be possible. This is why these optimization procedures are so helpful."
      ],
      "metadata": {
        "id": "3Loe3VzSgagP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Exercise 2\n",
        "\n",
        "Try to modify ``x0_val`` and ``x1_val`` in the above code, as well as the ``learning_rate`` and ``t`` initialization value, and see how it affects convergence. Get an intuition on simple example, it is very useful!\n",
        "\n",
        "Try to see when\n",
        "1. convergence is too slow\n",
        "2. oscillation near minimum occurs\n",
        "3. divergence\n"
      ],
      "metadata": {
        "id": "EFq8fqLkgRdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_FujCL3sgRhu"
      }
    }
  ]
}