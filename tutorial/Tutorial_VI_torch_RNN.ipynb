{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "name": "Tutorial_VI_torch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PCKy-0EotsrX",
        "y7-p8ClctsrY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbpit0_rtspv"
      },
      "source": [
        "# Tutorial VI: Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Fr8e3Ltspx"
      },
      "source": [
        "<p>\n",
        "Bern Winter School on Machine Learning, 2024<br>\n",
        "Prepared by Mykhailo Vladymyrov.\n",
        "</p>\n",
        "\n",
        "This work is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Upuaj8tspy"
      },
      "source": [
        "In this session we will see what RNN is. We will use it to predict/generate text sequence, but same approach can be applied to any sequential data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QUO3V3Stspz"
      },
      "source": [
        "So far we looked at the data available altogether. In many cases the data is sequential (weather, speach, sensor signals etc).\n",
        "RNNs are specifically designed for such tasks.\n",
        "\n",
        "<img src=\"https://github.com/neworldemancer/BMLWS/raw/main/figures/rnn.png\" alt=\"drawing\" width=\"90%\"/><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGyY2JPXtsq7"
      },
      "source": [
        "## 1. Load necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkz4sJrWTQRi"
      },
      "source": [
        "colab = True # set to True is using google colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpRETZFNtsq7"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipyd\n",
        "import collections\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.hub import download_url_to_file\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# We'll tell matplotlib to inline any drawn figures like so:\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH0SSbAftsq1"
      },
      "source": [
        "## unpack libraries\n",
        "if using colab, run the next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grv04xmitsq2"
      },
      "source": [
        "if colab:\n",
        "    path = os.path.join(os.path.abspath('.')+'material.tgz')\n",
        "    url = 'https://github.com/neworldemancer/BMLWS/raw/main/tut_files/tpub0320.tgz'\n",
        "    # p = tf.keras.utils.get_file(path, url)\n",
        "    # Download compressed file with torch utils\n",
        "\n",
        "    download_url_to_file(url=url, dst=path)\n",
        "\n",
        "    tar = tarfile.open(path, \"r:gz\")\n",
        "    tar.extractall()\n",
        "    tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "eu-yvNbfIBE0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7FnR5Kwtsq9"
      },
      "source": [
        "## 2. Load the text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3cmvKeatsq-"
      },
      "source": [
        "def read_data(fname):\n",
        "    with open(fname) as f:\n",
        "        content = f.readlines()\n",
        "    content = [x.strip() for x in content]\n",
        "    content = [word for i in range(len(content)) for word in content[i].split()]\n",
        "    content = np.array(content)\n",
        "    return content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4KJQxKqtsrA"
      },
      "source": [
        "book_file = 'RNN/rnn.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMumjsH8tsrD"
      },
      "source": [
        "book_words = read_data(book_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_GMc64ptsrF"
      },
      "source": [
        "print(book_words[:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Build dataset\n",
        "We will assign an id to each word, and make dictionaries word->id and id->word.\n",
        "The most frequently repeating words have the lowest id"
      ],
      "metadata": {
        "collapsed": false,
        "id": "duo-_uHPIBE3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_dictionaries(words):\n",
        "    count = collections.Counter(words).most_common()\n",
        "    dictionary = {}\n",
        "    for word, _ in count:\n",
        "        dictionary[word] = len(dictionary)\n",
        "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
        "    return dictionary, reverse_dictionary"
      ],
      "metadata": {
        "id": "6uzBG4b3IBE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "dictionary, reverse_dictionary = build_dictionaries(book_words)\n",
        "vocab_size = len(dictionary)"
      ],
      "metadata": {
        "id": "pOfVVdkeIBE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(dictionary)"
      ],
      "metadata": {
        "id": "Mts6-hKUIBE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then the whole text will look as a sequence of word ids:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "diEHIzudIBE5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def text_to_ints(text):\n",
        "    if type(text) == str:\n",
        "        text = text.split()\n",
        "    return [dictionary[w] for w in text]\n",
        "\n",
        "def ints_to_text(arr):\n",
        "    return ' '.join([reverse_dictionary[it] for it in arr])"
      ],
      "metadata": {
        "id": "1AC4lirIIBE5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "words_as_int = text_to_ints(book_words)\n",
        "print(words_as_int)\n",
        "\n",
        "print(len(words_as_int))\n",
        "print(ints_to_text(words_as_int[:100]))"
      ],
      "metadata": {
        "id": "DiDAmkX5IBE5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ojvV71pHJ6"
      },
      "source": [
        "## 3. Data streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_EYsL_TVaBz"
      },
      "source": [
        "Here we will see how to feed a dataset for model training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class WordDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, words_as_int, n_input):\n",
        "    self.words_as_int = words_as_int\n",
        "    self.n_input = n_input\n",
        "\n",
        "    self.block_len = self.n_input + 1\n",
        "    self.n_block = len(self.words_as_int) // self.block_len\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    #return len(self.words_as_int) - self.n_input - 1\n",
        "    return self.n_block\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    #return self.words_as_int[idx:idx+self.n_input+1]\n",
        "    start = idx * self.block_len\n",
        "    end = start + self.block_len\n",
        "    return self.words_as_int[start:end]"
      ],
      "metadata": {
        "id": "iejO2P_oIBE6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muEoZW05nFQt"
      },
      "source": [
        "# make preprocessing function converting data to torch tensors\n",
        "def preprocess(list_word_seq):\n",
        "    # Make random crops of the sequences n_input+1 length,\n",
        "    # obtain the input sequence and the target sequence\n",
        "\n",
        "    # Separate the input and target sequences\n",
        "    data = [word_seq[:-1] for word_seq in list_word_seq]\n",
        "    labels = [word_seq[1:] for word_seq in list_word_seq]\n",
        "\n",
        "    # stack the data and labels into NumPy arrays along the batch dimension (axis 1, SBC format)\n",
        "    data = np.stack(data, axis=1)\n",
        "    labels = np.stack(labels, axis=1)\n",
        "\n",
        "    # Convert NumPy arrays to PyTorch tensors\n",
        "    # and move them to the specified device (e.g., GPU)\n",
        "    data_t = torch.tensor(data, dtype=torch.long).to(device)\n",
        "    labels_t = torch.tensor(labels, dtype=torch.long).to(device)\n",
        "\n",
        "    return data_t, labels_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "n_input = 3  # word sequence to predict the following word\n",
        "batch_size = 50\n",
        "\n",
        "# make data loader\n",
        "\n",
        "dataset = WordDataset(words_as_int, n_input)\n",
        "train_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                           batch_size=batch_size, shuffle=True,\n",
        "                                           collate_fn=preprocess)"
      ],
      "metadata": {
        "id": "08KR6kpwIBE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "kiXemuTFyADO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique = set([tuple(dataset[i]) for i in range(len(dataset))])\n",
        "len(unique)"
      ],
      "metadata": {
        "id": "bXuR69Vn13jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model will predict input_text -> target_text:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "P8PjYaTvIBE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# test data loader\n",
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    print(data.shape, target.shape)\n",
        "\n",
        "    for data_np, tgt_np in zip(data.cpu().numpy().T, target.cpu().numpy().T):\n",
        "        data_str = ints_to_text(data_np)\n",
        "        target_str = ints_to_text(tgt_np)\n",
        "        print(f'{data_str}    ->    {target_str}')\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "lkLMVTbTIBE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Construct model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "v34AGLiaIBE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will build the model in Torch.\n",
        "It will contain an embedding layer, and three LSTM layers.\n",
        "Dense layer on top is used to output probability of the next word:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "n538eVAGIBE8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, lstm_hidden_dim):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "\n",
        "        if type(lstm_hidden_dim) == int:\n",
        "          lstm_hidden_dim = [lstm_hidden_dim]\n",
        "\n",
        "        self.rnn = []\n",
        "        for i, hidd_d in enumerate(lstm_hidden_dim):\n",
        "          prev_d = embedding_dim if i == 0 else lstm_hidden_dim[i-1]\n",
        "          rnn = nn.LSTM(prev_d, hidd_d, batch_first=True)\n",
        "          self.add_module(f'lstm_{i}', rnn)  # add_module is needed to register module in model, so that it can be found by model.parameters()\n",
        "          self.rnn.append(rnn)\n",
        "\n",
        "        self.fc = nn.Linear(hidd_d, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = F.relu(self.embedding(x))\n",
        "        for rnn in self.rnn:\n",
        "            embedded, (hidden_hn, hidden_cn) = rnn(embedded)\n",
        "            #print(embedded.shape, hidden_hn.shape, hidden_cn.shape)\n",
        "\n",
        "        output = embedded\n",
        "        rnn_out = output\n",
        "        return self.fc(rnn_out)"
      ],
      "metadata": {
        "id": "DyK69SbTIBE8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Parameters\n",
        "n_input = 3  # word sequence to predict the following word\n",
        "\n",
        "# number of units in RNN cells\n",
        "lstm_hidden_dim = [256, 512, 128]\n",
        "\n",
        "model = RNN(vocab_size=vocab_size, embedding_dim=128, lstm_hidden_dim=lstm_hidden_dim).to(device)"
      ],
      "metadata": {
        "id": "dJ163LpHIBE9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "x = words_as_int[:5]\n",
        "\n",
        "x = torch.tensor(x, dtype=torch.long).to(device)\n",
        "print('singe sample shape:', x.shape)\n",
        "x = x.unsqueeze(1)  # add batch dimension. By default, in torch LSTM expects input of shape (seq_len, batch, input_dim)\n",
        "print('batch shape:', x.shape)\n",
        "\n",
        "writer = SummaryWriter('runs/inspect_RNN')\n",
        "writer.add_graph(model, x)\n",
        "writer.close()\n",
        "\n",
        "y = model(x)\n",
        "print('output shape:', y.shape)"
      ],
      "metadata": {
        "id": "m4L8vcoZIBE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs/inspect_RNN"
      ],
      "metadata": {
        "id": "hD7o-ZUTyv33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test not trained model:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "jBbq8MltIBE9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    break"
      ],
      "metadata": {
        "id": "eFlrnhOzIBE-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "pred = model(data)\n",
        "print(pred.shape)"
      ],
      "metadata": {
        "id": "Bxl2IpFBIBE-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# get word ids with highest probability\n",
        "pred_ids = pred.detach().cpu().numpy().argmax(axis=2)"
      ],
      "metadata": {
        "id": "C3HV_z34IBE-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "print('input: ', ints_to_text(data.cpu().numpy()[:, 0]))\n",
        "print('output:', ints_to_text(target.cpu().numpy()[:, 0]))\n",
        "print('pred:  ', ints_to_text(pred_ids[:, 0]))\n"
      ],
      "metadata": {
        "id": "MaGYJk37IBE_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aqxQ_X-tsrV"
      },
      "source": [
        "## 5. Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7wT782Hrq-R"
      },
      "source": [
        "# Parameters\n",
        "n_input = 3  # word sequence to predict the following word\n",
        "batch_size = 50\n",
        "\n",
        "# make data loader\n",
        "\n",
        "dataset = WordDataset(words_as_int, n_input)\n",
        "train_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                           batch_size=batch_size, shuffle=True,\n",
        "                                           collate_fn=preprocess)\n",
        "\n",
        "# number of units in RNN cells\n",
        "lstm_hidden_dim = [128]\n",
        "\n",
        "model = RNN(vocab_size=vocab_size, embedding_dim=128, lstm_hidden_dim=lstm_hidden_dim).to(device)\n",
        "\n",
        "# Define the sparse cross-entropy loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "n_epochs = 200\n",
        "\n",
        "loss_hist = []\n",
        "acc_hist = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.\n",
        "\n",
        "    model.train()\n",
        "    correct = []\n",
        "    for batch in train_loader:\n",
        "        data, labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        # labels are of shape (seq_len, batch_size), output is of shape (seq_len, batch_size, vocab_size)\n",
        "        # we need to reshape labels to (seq_len*batch_size) and output to (seq_len*batch_size, vocab_size)\n",
        "        # (they are torch tensors, so we can use view() method)\n",
        "\n",
        "        output_f = output.view(-1, vocab_size)\n",
        "        labels_f = labels.view(-1)\n",
        "\n",
        "        loss = criterion(output_f, labels_f)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        pred_class = torch.argmax(output, dim=2)\n",
        "        corr = pred_class == labels\n",
        "        correct.append(corr.detach().cpu().numpy())\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    loss_hist.append(train_loss)\n",
        "\n",
        "    correct = np.concatenate(correct, axis=1)\n",
        "    accuracy = np.mean(correct)\n",
        "\n",
        "    acc_hist.append(accuracy)\n",
        "\n",
        "    print(f\"{epoch}:\\t Test loss: {train_loss}; accuracy: {accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the RMSProp optimizer is used here, leading to faser convergence in this case than Adam/AdamW"
      ],
      "metadata": {
        "id": "FB-zlUdg7NYD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dan-chKsvbU"
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "axs[0].semilogy(loss_hist)\n",
        "axs[0].set_xlabel('epoch')\n",
        "axs[0].set_ylabel('loss')\n",
        "axs[0].set_title('Loss history')\n",
        "axs[1].plot(acc_hist)\n",
        "axs[1].set_xlabel('epoch')\n",
        "axs[1].set_ylabel('accuracy')\n",
        "axs[1].set_title('Accuracy history')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BldvImFYfm4"
      },
      "source": [
        "## 6. Generating text with RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3kuXO1jYu-a"
      },
      "source": [
        "Take word sequence and generate the following 128 words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def gen_long(model, word_id_arr, n_words=128):\n",
        "  out = []\n",
        "  words = list(word_id_arr.copy())\n",
        "  with torch.no_grad():\n",
        "      for i in range(n_words):\n",
        "          seq = torch.tensor(words, dtype=torch.long).unsqueeze(1).to(device)\n",
        "          pred = model(seq)\n",
        "          pred_class = torch.argmax(pred, dim=2)\n",
        "          pred_class_np = pred_class.detach().cpu().numpy()\n",
        "          pred_class_np = pred_class_np[:, 0]  # take only first element of batch\n",
        "\n",
        "          next_word_idx = pred_class_np[-1]  # take last word of sequence\n",
        "          words.append(next_word_idx)\n",
        "\n",
        "  sentence = ints_to_text(words)\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "m7PF0j0IIBFL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7gzaQ1FyRCE"
      },
      "source": [
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "  input_seq = data.cpu().numpy()[:, 0]\n",
        "  sentence = gen_long(model, input_seq)\n",
        "  print(ints_to_text(input_seq), '...')\n",
        "  print('\\t...', sentence, '\\n')\n",
        "\n",
        "  if batch_idx > 5:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGv_d3bzZB9a"
      },
      "source": [
        "Or try to input some text and see continuation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "try:\n",
        "    sentence = input(\"few words\")\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "sentence = sentence.strip()\n",
        "words = sentence.split(' ')\n",
        "\n",
        "try:\n",
        "    symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
        "except:\n",
        "    print(\"Word not in dictionary\")\n",
        "\n",
        "sentence = gen_long(model, symbols_in_keys)\n",
        "print(sentence)"
      ],
      "metadata": {
        "id": "mvSjOjMfIBFM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "_iX7hcrFtsrW"
      },
      "source": [
        "while True:\n",
        "    prompt = \"%s words: \" % n_input\n",
        "\n",
        "    try:\n",
        "      sentence = input(prompt)\n",
        "    except KeyboardInterrupt:\n",
        "      break\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "    words = sentence.split(' ')\n",
        "    # if len(words) != n_input:\n",
        "    #     continue\n",
        "    try:\n",
        "        symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
        "    except:\n",
        "        print(\"Word not in dictionary\")\n",
        "        continue\n",
        "\n",
        "    sentence = gen_long(model, symbols_in_keys)\n",
        "    print(sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCKy-0EotsrX"
      },
      "source": [
        "## 7. Exercise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYXY5jfMAi6x"
      },
      "source": [
        "* Run with 5-7 input words instead of 3.\n",
        "* increase number of training iterations, since convergance will take much longer (training as well!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7-p8ClctsrY"
      },
      "source": [
        "## 8. Further reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjhwEgdKtsrZ"
      },
      "source": [
        "[Illustrated Guide to Recurrent Neural Networks](https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9)\n",
        "\n",
        "[Illustrated Guide to LSTM’s and GRU’s: A step by step explanation](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n",
        "\n",
        "[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xURlW6tlUHYI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}